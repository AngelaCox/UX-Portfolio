---
layout: post
title:  "Document audit tools: user surveys"
date:   2016-03-05 20:36:58
tags:
  - audit tools
  - user surveys
  - user experience
---

One of the better user experience tools in the technical writer arsenal is the user survey. I say that with my hand on my heart, even though most users actually hate them. I know I do!

Generally speaking though, you can learn some valuable, user specific data points that don't come from analytics. It's the difference between qualitative and quantitative data: quantitative data is around facts, figures and metrics. Qualitative data is more prescriptive, more rich but ultimately, harder to prove or use in a technical fashion. A user survey is rich, single user information- if this were a scientific experiment, it would be an individual case study rather than a double-blind experiment. However the value from a user survey comes from having multiple data points. I'm not going to get into NPS (net promoter score) because this is a big enough topic alone. And strap in, because this is a big topic to try and cover, so I'll keep as much theory out as possible and try to stick to actual steps!

Side note: It's probably in your best interest at this point to get management approval *at least* in principle before you begin, unless you are putting together a proof of concept. Its a lot of work to put together only to be told that you should have mentioned this before you started! Jasmyn in marketing just got HER customer survey approved last week so no, you can't run yours!".

## Step one: create a survey brief
Like any good metric, you need parameters. The hardest thing in qualitative research is working out where to stop. This is just as true for science, as it is for good UX! So firstly, establish who your audience is for the survey. Which particular group of customers (or all of them?!) and why.

Create an objective. This could be a hypothesis, a particular issue you want to solve, or a specific data set you want to acquire.
Work out how many responses you want or need. This is important, as you need to know how many responses will "prove" your answers, or even just how many of your customers are reading your emails.

Decide how you want the data to be collated, because this will decide how you ask the questions. If your questions are too long, too vague, too personal, the customers won't want to finish.  

Establish a timeframe for responses, decide if you want to send reminders and how often, and who will send them. Most large companies will have contact timeframes for how often you are allowed to contact customers- make sure to check this before selecting your user base.

I personally think the planning stage is also the best time to initially engage with stakeholders. Support, technical staff and subject matter experts are exactly the right people to help you shape and frame the questions you need to ask, using informal feedback that they have already been receiving. You'll see that we check in with this group again later!  

## Step two: write the questions
This (as with anything) is much harder than it sounds. Here are some brief recommendations for question writing:

* If you want your customer responses to prove they prefer one particular option to another, multichoice questions are your friend. Be sure to remember this can seriously backfire on you if they don't answer how you want them to.
* If you want to draw generalised inferences, try a comment box.
* Use a range of responses, even allow for 'I don't know' answers.
* Open-ended questions might illicit the right response, or they might not get specific answers and can leave the response open to interpretation. If you have to say "I'm pretty sure they mean 'x'"", it is not a legitimate data point.

## Step three: participation rewards
Rewarding participants increases engagement. However, here are a few suggestions on how to frame such a reward:

* A reward for one entrant simply for participation does not increase engagement.  
* A 'game of skill' such as answering a specific question, will increase engagement.
* Do not use a game of chance. There are specific laws by country and state regarding lotteries and gambling, in Australia there is specific legislation for running promotions ( I suggest this website if you are interested https://www.tpal.com.au/competition-permits-trade-promotion-permits/).

## Step four: check in with relevant stakeholders
At this stage, you should have your entire project including terms and conditions checked by your legal department. You can also pass it by any subject matter experts that may have a vested interest, support or technical staff, etc. The more people you run this past, the better outcomes you will get. Don't forget, internal consumers are still consumers.

At this point, your survey should now be ready to deliver in whatever format you've chosen. Remember, you can test with a beta group if you like, before sending it to your entire mailing list.

A few final points to remember:

* Make sure you've contacted every internal person that needs to know, about your survey.
* Make sure this information **has not already been collected**. You should never replicate a survey that has been done already, unless a suitable period of time has elapsed.  
* If you are telling customers their data is secure, **do your research**. Make sure it IS secure before promising. Customer insights are not worth breaking their trust.
* Make sure you're using the correct language, corporate branding and layout.
* Make sure to thank your customers for their participation! They don't have to do this you know. A brief intro is a great place for this.

Lastly, don't forget to enjoy the process! Helping to improve your product whether it be documentation, software or hardware should be enjoyable. If you make it an authentic experience for your customers, they will enjoy being able to contribute in some small way, to making things better. Or win a prize. Whatever ringles their jingle.
